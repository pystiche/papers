\section{Introduction}

In the visual arts, especially painting, people have mastered the ability to create unique visual experiences by composing a complex interplay between the content and style of a painting. The algorithmic basis of this process, if it exists at all, is still unknown. One could think about solving this task with a traditional supervised learning approach, the learned style transfer requires a pair of input images i. e. both an original image and an artistic representation of this original image. From there, a machine learning model learns the transformation and can apply it to new original images. Unfortunately, this approach is largely impractical, as these kinds of image pairs rarely exist.
 
However, in recent years, there are artificial systems that generate artistic images of high perceptual quality based on Deep Learning (DL) algorithms. This technique of recomposing images in the style of other images is called Neural Style Transfer (NST) and was introduced by Gatys, Ecker and Bethge in 2016 \cite{GEB2016}. An example of a content image receiving the style and a style image from which the style is transferred, as well as the result of the NST, can be seen in \figref{fig_nst}. With recent advances in technologies like style transfer, almost anyone can enjoy the pleasure that comes with creating and sharing an artistic masterpiece. This is where the transformative power of style transfer lies. By using the NST as a more complex image filter, it empowers people around the world to experiment with their own creativity. On the other hand, the significance can also be observed in the commercial art world. In 2018, Christie's featured AI artwork sold at one of their auctions for more than $\$430.000$ \cite{2018}. By using style transfer to recorded and live video, NST opens many doors in design, content creation, and creative tool development. For example, NST can be applied in various ways to photo and video editors, virtual reality, gaming and commercial art.
     
\begin{figure*}[!t]
	\centering
	\includestandalone{nst/example_images}
	\caption{Example of the neuronal style transfer with the content image (left), the used style image (middle) and the stylised image (right).}
	\label{fig_nst}
\end{figure*}

If the NST approach from \cite{GEB2016} would work flawlessly, it could be used to achieve the complex interplay between content and style in an image, as is done by artists in the visual arts. Since this is not the case in practice, countless variants of the original formulation have already been published. These range from one-shot approaches, in which a single image is stylised with the help of an optimisation algorithm \cite{GEB2016, LW2016, GEB+2017,  ML2019}, to iterative approaches \cite{JAL2016,ULVL2016,UVL2017, SKLO2018}, in which a transformer is learned that can subsequently transform an input image into a stylised output image. A comprehensive overview of NST methods is given by Jing et al. \cite{JYF+2019}.

The NST has become a trending topic in academic literature in recent years, with a wide range of possible approaches to perform the style transfer. This is underlined by the number of citations to the initial paper "Image style transfer using convolutional neural networks" \cite{GEB2016}. In the past 5 years, according to Google Scholar\urlfootnote{Overview of the papers in which the paper or preprint is referenced}{https://scholar.google.de/scholar?oi=bibs&hl=en&cites=15430064963552939126,6343685530593283491,788840246532963346,18334534842043149041}{16.03.2021}, this paper has been cited over 4000 times. The problem with such a rapid development of publications is the lack of standardisation, which is usually introduced after the initial boom. Without a standardisation, the approaches exist in different programming languages as well as DLFs. This makes a direct combination impossible and a comparison of the methods difficult, although the authors of the methods provide the source code of their approaches.
 
Consequently, the authors of the papers have only two approaches to compare their results with other methods. On the one hand, the other approaches themselves can be implemented from scratch. This approach is error-prone, as discrepancies between implementations can be introduced due to the lack of knowledge about other Deep Learning Frameworks (DLFs) or implementation errors. On the other hand, the code of the original authors can be used. The problem of this approach is that small implementation errors are carried over, and so the errors are integrated into all subsequent publications. During the review of the reference implementations, we also noticed that there are discrepancies between the published algorithm and the provided implementation. These range from incorrectly specified or not specified hyperparameters to minor implementation errors to significant changes in the algorithms compared to the publications. This makes an exact replication of the results considerably more difficult or even impossible. We suggest that the discrepancies are not deliberate deceptions but rather artefacts due to lack of standardisation.

Based on these observations, two steps have been taken. First, the introduction of standardisation for the NST implementation. For this purpose the public NST library with the name \texttt{pystiche} was created \cite{ML2020}. This library requires only a minimum of prior knowledge about NST and DL and is also flexible enough to combine the different approaches and does not limit the scope of action. The \texttt{pystiche} library is based on and is fully compatible with the NST PyTorch \cite{PGM+2019}. Second, this replication study of known NST approaches has subsequently been carried out. We have replicated a total of seven known NST procedures based on the library \texttt{pystiche}. Due to the differences between the paper and the reference implementation, the figures from the original paper with the respective information are carried out in this replication study. This highlights the open problem of lack of replicability and reinforces the need for standardisation.

The paper is structured as follows. The next section briefly introduces the implementations replicated in this paper and the reason for selecting them. The following section explains the discrepancies found between the implementations and the paper. Finally, the results and their significance are discussed.