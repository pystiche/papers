\section{Replicated Paper} \label{sec:replicated_paper}

There is a large number of different publications and small improvements to individual algorithms. For this reason, this study reproduces the basic algorithms with new innovative approaches. The approaches differed essentially according to the category, whether it is an image-based approach or a model-based approach. In the image-based approaches, the stylised images are created in an iterative process by an optimisation process. This process has to be performed for each individual image, which means that these approaches are slow, but that the results can be better adapted. In contrast, in model-based approaches, a model is trained in advance, which can then stylise any input image in real-time. An overview of the replicated algorithms can be found in \tabref{tab:used_methods}. 

As can be seen from the \tabref{tab:used_methods}, another major difference between the individual approaches is the choice of style model. The style of an image includes structural elements such as brushstrokes, colours, and contrast. These texture features can be described after \cite{Zho2006} with two different approaches. On the one hand, a stochastic approach which assumes that if global statistics of the images match, the underlying textures also match. On the other hand, a structural approach which assumes that a texture can be described by the regular or irregular joining of small patches. For both approaches there are approaches in the NST. For this reason, first of all, the algorithm that initiated the NST has been replicated. The approach of Gatys, Ecker and Bethge follows an approach based on global statistics \cite{GEB2016}. In contrast to this, the approach of Li and Wand covers the fundamentally different approach of the structural approach \cite{LW2016}. Both methods are an image-based approach in which the pixels of the image to be stylised are iteratively adjusted by an optimisation problem. To increase the usefulness of the NST as an artistic tool, it is important that the user can easily and intuitively control the output of the algorithm. For this reason the approach from \cite{GEB+2017} has been replicated. They show that their method enables high-resolution controlled stylisation and helps mitigate common error cases such as applying ground textures to sky regions. This means that a region-to-region condition can be added to the style transfer by using a mask. This additional condition ensures that, for example, the eye in the content image is stylised in the same way as the eye in a painting and unwanted artefacts due to local fitting errors are reduced.

\begin{table*}[!t]
	\renewcommand{\arraystretch}{1.3}
	\caption{Overview of replicated methods, their categorisation and the model used for the style.}
	\label{tab:used_methods}
	\centering
	\resizebox{\textwidth}{!}{%
	\begin{tabular}{c|c|c}
		\hline
		\bfseries Methods & \bfseries 
		Categorisation & \bfseries Style Model\\
		\hline\hline
		Gatys, Ecker and Bethge \cite{GEB2016} & & stochastic \\
		Li and Wand \cite{LW2016} & image-based & structural\\
		Gatys et al. \cite{GEB+2017}  & &  stochastic with additional region condition\\
		\hline
		Johnson et al. \cite{JAL2016} & & stochastic\\
		Ulyanov et al. \cite{ULVL2016,UVL2017} & model-based &  stochastic\\
		Sanakoyeu et al. \cite{SKLO2018} & & population\\
		\hline
	\end{tabular}}
\end{table*}

The previous methods are very slow because for each individual image an optimisation problem must be solved iteratively. For this reason, algorithms exist with which a style transfer can be carried out in real time. The basic idea is to train a network, the so-called transformer, in order to be able to use it for style transfer afterwards. The first two model-based approaches are proposed by Johnson et al. \cite{JAL2016} and Ulyanov et al. \cite{ULVL2016} respectively. They only differ in the transformer architecture, for which Johnson et al. design a feed-forward network, and Ulyanov et al. use a pyramid-shaped structure. While models of the feed-forward network type by Johnson work with only one image resolution, the pyramid-shaped structure work with multiple resolutions simultaneously. It is also worth noting that in Ulyanov et al. in the 2017 follow up publication, it was found that replacing batch normalisation with instance normalisation and applying instance normalisation to both training and testing leads to even faster real-time performance and arguably more aesthetically pleasing results \cite{UVL2017}. Since these differ essentially only in the choice of norm, this paper is also included in the replication study.

An alternative training method of a transformer is from Sanakoyeu et al. in \cite{SKLO2018}. They use a so-called Generative Adversarial Network (GAN) for the style transfer. A GAN consists of two networks that perform a zero-sum game. In the case of NST, one network (the transformer) is trained to produce the fake style images, whereas the second network (the discriminator) evaluates these images according to a discriminative model. While the discriminator learns to distinguish the fake images created by the transformer from the original style images, the transformer learns to create better fake images and make the second one give a bad answer. This in turn is used to gradually improve the evaluation method of the discriminator. The training is successful when the discriminator is no longer able to distinguish an image created by the transformer from the original style images. The big advantage of using GANs is that this approach is no longer limited to one style image. This makes sense because a style cannot be described in terms of one instance, but can rather be divided into groups or epochs. For example, several pictures of a painter can be grouped for the style transfer, in order to get a more comprehensive overview of the style. Since this method is not to be attributed to the structural or stochastic style approach, we call it the population approach, since here we train to optimise the style transfer from a population of style images.

The procedures briefly presented above are part of the replication study and are published as a Python package \texttt{pystiche\_papers}. The source code\footnote{\url{https://github.com/pmeier/pystiche_papers}} as well as the documentation\footnote{\url{https://pystiche-papers.readthedocs.io}} of \texttt{pystiche\_papers} are available online. 