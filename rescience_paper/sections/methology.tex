\section{Methodology of Replicability}

In this study, we have implemented the NST approaches presented in \secref{sec:replicated_paper} based on the NST library \texttt{pystiche} \cite{ML2020} in \texttt{pyTorch}. Due to the differences between the paper and the reference implementation presented in \secref{sec:replicability}, we have replicated the images with the default implementation parameters and with the information given in the paper. Although the authors have incorporated further images from additional experiments in the paper, we have only replicated the images that show the result of the underlying approach in order to determine whether the replication of the approach is successful. 

\subsection{Parameters}

We have used the hyperparameters given in the original papers. An overview of the parameters used can be found in the tables in the \secref{sec:parameters_appendix}. The tables contain the information of the authors published in their paper and the default values from the implementation. Furthermore, a detailed documentation of the hyperparameters used can be found in the documentation of \texttt{pystiche\_papers}. The deviations between the parameters described in the paper and the original implementation are marked by comments. In addition, links are provided with the location of the deviation in an archived version of the original implementation at the time of this replication study.

Since the hyperparameters are meant to change the style transfer, different parameter values may be used for individual images or trainings that differ from the default values. The specification of these adjusted values can also be found in \secref{sec:parameters_appendix} for the respective style images.

\subsection{Data} \label{sec:data}

The authors of the original approaches use different content and style images as well as different datasets for the training of the models in the model-based methods. In order to compare the replicated images, we use the images used in the original papers for the verification of the replication. Some of the images are available in the original github repository. The images that have not been made accessible have been selected as a result of an image search. Links and license information are available in the implementation for these images. We have only used images whose license information allows them to be used in a scientific work.

For the training of model-based methods, the different datasets used for the respective implementation are listed in \tabref{tab:datasets}. Each training image is preprocessed according to the steps specified in the paper or the reference implementation. This includes for example image augmentation and cropping of the images. Information on this can be found in the tables in \secref{sec:parameters_appendix}.

The following datasets are required for this replication study:

\begin{itemize}
	\item The Microsoft Common Objects in Context (MS COCO) dataset contains 164K images. The size of the dataset is 25 GB \cite{LMB+2014}.\urlfootnote{Source}{https://cocodataset.org}{28.09.2021}
	\item The Large Scale Visual Recognition Challenge 2012 (ILSVR2012) is a subset of ImageNet containing 1000 categories and 1.2 million images. The size of the dataset is 154.6 GB \cite{RDS+2015}.\urlfootnote{Source}{https://image-net.org/challenges/LSVRC/2012/}{28.09.2021}
	\item The Places365 contains 365 categories and 1.8 million images. The size of the dataset is 105 GB \cite{ZLX+2014}.\urlfootnote{Source}{http://places2.csail.mit.edu/download.html}{28.09.2021}
\end{itemize}

\begin{table*}[t]
	\renewcommand{\arraystretch}{1.3}
	\caption{Overview of the datasets required for the replicated paper.}
	\label{tab:datasets}
	\centering
	\begin{tabular}{c|c}
		\hline
		\bfseries Methods & \bfseries Dataset\\
		\hline\hline
		Johnson et al. \cite{JAL2016} & MS COCO  \\
		Ulyanov et al. \cite{ULVL2016} & ILSVRC2012$^1$ \\
		Ulyanov et al. \cite{UVL2017} & ILSVRC2012 \\
		Sanakoyeu et al. \cite{SKLO2018} & Places365$^2$\\
		\hline
	\end{tabular}
\footnotesize{
	\\$^1$ Only the validation set is specified in the reference implementation.
	\\$^2$ A reduced number of classes is used in the reference implementation.
}
\end{table*}

\subsection{Computional requirements}

All our final replication scripts were performed on a machine having a Titan RTX CUDA GPU with 24 GB memory. A GPU with a lot of memory is particularly needed for model-based approaches. Our CUDA version is $11.0$ and the Nvidia driver version is $450.51.06$. The implementation also requires different libraries, which are listed in the  \tabref{tab:libraries} with the version used. In addition, the datasets used must be available. 

\begin{table*}[t]
	\renewcommand{\arraystretch}{1.3}
	\caption{Overview of the libraries used with the version used at the time of replication.}
	\label{tab:libraries}
	\centering
	\begin{tabular}{c|c}
		\hline
		\bfseries Library & \bfseries Version\\
		torch & 1.7.0+cu101\\
		torchvision &  0.8.0+cu101\\
		pystiche & 1.0.0\\
		pillow & 8.0.1\\
		numpy & 1.19.4\\
		more-itertools & 8.6.0\\
		kornia & 0.4.1 \\
		\hline
	\end{tabular}
\end{table*}