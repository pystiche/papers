from abc import abstractmethod
from collections import OrderedDict
from typing import Iterator, Optional, Sequence, Tuple, Union, cast

import torch
import torch.nn.functional as F
from torch import nn

import pystiche
from pystiche import enc, ops
from pystiche.enc import Encoder, MultiLayerEncoder
from pystiche_papers.sanakoyeu_et_al_2018._modules import ConvBlock, conv
from pystiche_papers.utils import channel_progression

__all__ = [
    "Discriminator",
    "DiscriminatorMultiLayerEncoder",
    "prediction_module",
    "EncodingDiscriminatorOperator",
    "PredictionOperator",
    "MultiLayerPredictionOperator",
    "prediction_loss",
]


class Discriminator(pystiche.Module):
    r"""Discriminator from :cite:`SKL+2018`.

    Args:
        in_channels: Number of channels in the input. Defaults to ``3``.
    """

    def __init__(self, in_channels: int = 3) -> None:
        super().__init__(
            indexed_children=channel_progression(
                lambda in_channels, out_channels: ConvBlock(
                    in_channels,
                    out_channels,
                    kernel_size=5,
                    stride=2,
                    padding=None,
                    act="lrelu",
                ),
                channels=(in_channels, 128, 128, 256, 512, 512, 1024, 1024),
            )
        )


class DiscriminatorMultiLayerEncoder(enc.MultiLayerEncoder):
    r"""Discriminator from :cite:`SKL+2018` as :class:`pystiche.enc.MultiLayerEncoder`.

    Args:
        in_channels: Number of channels in the input. Defaults to ``3``.
    """

    def __init__(self, in_channels: int = 3) -> None:
        super().__init__(tuple(Discriminator(in_channels=in_channels).named_children()))


def prediction_module(
    in_channels: int, kernel_size: Union[Tuple[int, int], int],
) -> nn.Module:
    r"""Prediction module from :cite:`SKL+2018`.

    This block comprises a convolutional, which is used as an auxiliary classifier to
    capture image details on different scales of the :class:`DiscriminatorEncoder`.

    Args:
        in_channels: Number of channels in the input.
        kernel_size: Size of the convolving kernel.

    """
    return conv(
        in_channels=in_channels,
        out_channels=1,
        kernel_size=kernel_size,
        stride=1,
        padding=None,
    )


class EncodingDiscriminatorOperator(ops.EncodingRegularizationOperator):
    r"""Abstract base class for all discriminator operators working in an encoded space.

    Args:
        encoder: Encoder that is used to encode the input images.
        score_weight: Score weight of the operator. Defaults to ``1.0``.

    Attributes:
        real_images: Discriminator mode in whose dependence the output of the functions
            :func:`calculate_score` and :func:`calculate_accuracy` can be influenced.
            This can be either real or fake. The discriminator mode should not
            be set manually, but with the help of functions :func:`real` and
            :func:`fake`.
        accuracy: The accuracy of the discriminator at the last input.

    """

    def __init__(self, encoder: Encoder, score_weight: float = 1.0):
        super().__init__(encoder, score_weight=score_weight)
        self.real_images = True
        self.accuracy: torch.Tensor
        self.register_buffer("accuracy", torch.zeros(1))

    def real(self, mode: bool = True) -> "EncodingDiscriminatorOperator":
        r"""Sets the discriminator mode to real images.

        Args:
            mode: Whether to set the discriminator mode to real (``True``, default) or
                fake (``False``) images.
        """
        self.real_images = mode
        return self

    def fake(self) -> "EncodingDiscriminatorOperator":
        r"""Sets the discriminator mode to fake images."""
        return self.real(False)

    def process_input_image(self, image: torch.Tensor) -> torch.Tensor:
        input_repr = self.input_image_to_repr(image)
        self.accuracy = self.calculate_accuracy(input_repr)
        return self.calculate_score(input_repr)

    @abstractmethod
    def calculate_accuracy(self, input_repr: torch.Tensor) -> torch.Tensor:
        pass


class PredictionOperator(EncodingDiscriminatorOperator):
    r"""Partial discriminator loss based on :class:`torch.nn.BCELoss`.

    The class prediction is generated by the ``predictor``, which acts an
    auxiliary classifier.

    Args:
        encoder: Encoder that is used to encode the input images.
        predictor: Auxiliary classifier used to predict real or fake from the encodings
            of the ``encoder``.
        score_weight: Score weight of the operator. Defaults to ``1.0``.

    """

    def __init__(
        self, encoder: Encoder, predictor: nn.Module, score_weight: float = 1e0,
    ) -> None:
        super().__init__(encoder, score_weight=score_weight)
        self.predictor = predictor

    def input_enc_to_repr(self, enc: torch.Tensor) -> torch.Tensor:
        return cast(torch.Tensor, self.predictor(enc))

    def calculate_score(self, input_repr: torch.Tensor) -> torch.Tensor:
        return torch.mean(
            F.binary_cross_entropy_with_logits(
                input_repr,
                torch.ones_like(input_repr)
                if self.real_images
                else torch.zeros_like(input_repr),
            )
        )

    def calculate_accuracy(self, input_repr: torch.Tensor) -> torch.Tensor:
        comparator = torch.ge if self.real_images else torch.lt
        return torch.mean(comparator(input_repr, 0.0).float())


class MultiLayerPredictionOperator(ops.MultiLayerEncodingOperator):
    r"""Convenience container for multiple :class:`PredictionOperator` s.

    Args:
        multi_layer_encoder: Multi-layer encoder.
        layers: Layers of the ``multi_layer_encoder`` that the children operators
            operate on.
        get_encoding_op: Callable that returns a children operator given a
            :class:`pystiche.enc.SingleLayerEncoder` extracted from the
            ``multi_layer_encoder`` and its corresponding layer weight.
        layer_weights: Weights of the children operators passed to ``get_encoding_op``.
            If ``"sum"``, each layer weight is set to ``1.0``. If ``"mean"``, each
            layer weight is set to ``1.0 / len(layers)``. If sequence of ``float``s its
            length has to match ``layers``. Defaults to ``"mean"``.
        score_weight: Score weight of the operator. Defaults to ``1.0``.
    """

    def discriminator_operators(self) -> Iterator["EncodingDiscriminatorOperator"]:
        for op in self.operators():
            if isinstance(op, EncodingDiscriminatorOperator):
                yield op

    def real(self, mode: bool = True) -> "MultiLayerPredictionOperator":
        for op in self.discriminator_operators():
            op.real(mode)
        return self

    def fake(self) -> "MultiLayerPredictionOperator":
        return self.real(False)

    def get_accuracy(self) -> torch.Tensor:
        r"""Returns the average accuracy of all operators."""
        accuracies = torch.stack([op.accuracy for op in self.discriminator_operators()])
        return torch.mean(accuracies)


def prediction_loss(
    impl_params: bool = True,
    multi_layer_encoder: Optional[MultiLayerEncoder] = None,
    scale_weights: Union[str, Sequence[float]] = "sum",
    score_weight: Optional[float] = None,
) -> MultiLayerPredictionOperator:
    r"""Partial discriminator loss from :cite:`SKL+2018` for a single image.

    Capture image details at different scales with an auxiliary classifier and sum up
    all losses and accuracies on different layers of the
    :class:`~pystiche.enc.MultiLayerEncoder`.

    Args:
        impl_params: If ``True``, uses the parameters used in the reference
            implementation of the original authors rather than what is described in
            the paper.
        multi_layer_encoder: :class:`~pystiche.enc.MultiLayerEncoder`. If omitted, the
            default
            :class:`~pystiche_papers.sanakoyeu_et_al_2018.DiscriminatorMultiLayerEncoder`
            is used.
        scale_weights: Scale weights of the operator. Defaults to ``sum``.
        score_weight: Score weight of the operator. If omitted, the score_weight is
            determined with respect to ``impl_params``. Defaults to ``1e0`` if
            ``impl_params is True`` otherwise ``1e-3``.

    """
    if multi_layer_encoder is None:
        multi_layer_encoder = DiscriminatorMultiLayerEncoder()

    if score_weight is None:
        # https://github.com/pmeier/adaptive-style-transfer/blob/07a3b3fcb2eeed2bf9a22a9de59c0aea7de44181/main.py#L98
        score_weight = 1e0 if impl_params else 1e-3

    predictors = OrderedDict(
        (
            ("0", prediction_module(128, 5)),
            ("1", prediction_module(128, 10)),
            ("3", prediction_module(512, 10)),
            ("5", prediction_module(1024, 6)),
            ("6", prediction_module(1024, 3)),
        )
    )

    def get_encoding_op(
        encoder: enc.SingleLayerEncoder, layer_weight: float
    ) -> PredictionOperator:
        return PredictionOperator(
            encoder, predictors[encoder.layer], score_weight=layer_weight,
        )

    return MultiLayerPredictionOperator(
        multi_layer_encoder,
        tuple(predictors.keys()),
        get_encoding_op,
        layer_weights=scale_weights,
        score_weight=score_weight,
    )
