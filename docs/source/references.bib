% Encoding: UTF-8

@InProceedings{GEB2016,
  author    = {Gatys, Leon A. and Ecker, Alexander. S. and Bethge, Matthias},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
  title     = {Image Style Transfer Using Convolutional Neural Networks},
  year      = {2016},
  abstract  = {Rendering the semantic content of an image in different styles is a difficult image processing task. Arguably, a major limiting factor for previous approaches has been the lack of image representations that explicitly represent semantic information and, thus, allow to separate image content from style. Here we use image representations derived from Convolutional Neural Networks optimised for object recognition, which make high level image information explicit. We introduce A Neural Algorithm of Artistic Style that can separate and recombine the image content and style of natural images. The algorithm allows us to produce new images of high perceptual quality that combine the content of an arbitrary photograph with the appearance of numerous wellknown artworks. Our results provide new insights into the deep image representations learned by Convolutional Neural Networks and demonstrate their potential for high level image synthesis and manipulation.},
  doi       = {10.1109/CVPR.2016.265},
  eprint    = {1508.06576},
}

@InProceedings{LW2016,
  author    = {Li, Chuan and Wand, Michael},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
  title     = {Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis},
  year      = {2016},
  abstract  = {This paper studies a combination of generative Markov random field (MRF) models and discriminatively trained deep convolutional neural networks (dCNNs) for synthesizing 2D images. The generative MRF acts on higher-levels of a dCNN feature pyramid, controlling the image layout at an abstract level. We apply the method to both photographic and non-photo-realistic (artwork) synthesis tasks. The MRF regularizer prevents over-excitation artifacts and reduces implausible feature mixtures common to previous dCNN inversion approaches, permitting synthesizing photographic content with increased visual plausibility. Unlike standard MRF-based texture synthesis, the combined system can both match and adapt local features with considerable variability, yielding results far out of reach of classic generative MRF methods.},
  doi       = {10.1109/CVPR.2016.272},
  eprint    = {1601.04589},
}

@InProceedings{GEB+2017,
  author    = {Gatys, Leon A. and Ecker, Alexander S. and Bethge, Matthias and Hertzmann, Aaron and Shechtman, Eli},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
  title     = {Controlling Perceptual Factors in Neural Style Transfer},
  year      = {2017},
  abstract  = {Neural Style Transfer has shown very exciting results enabling new forms of image manipulation. Here we extend the existing method to introduce control over spatial location, colour information and across spatial scale. We demonstrate how this enhances the method by allowing high-resolution controlled stylisation and helps to alleviate common failure cases such as applying ground textures to sky regions. Furthermore, by decomposing style into these perceptual factors we enable the combination of style information from multiple sources to generate new, perceptually appealing styles from existing ones. We also describe how these methods can be used to more efficiently produce large size, high-quality stylisation. Finally we show how the introduced control measures can be applied in recent methods for Fast Neural Style Transfer.},
  doi       = {10.1109/CVPR.2017.397},
  eprint    = {1611.07865},
}

@InProceedings{JAL2016,
  author    = {Johnson, Justin and Alahi, Alexandre and Li, Fei-Fei},
  booktitle = {European Conference on Computer Vision ({ECCV})},
  title     = {Perceptual Losses for Real-Time Style Transfer and Super-Resolution},
  year      = {2016},
  doi       = {10.1007/978-3-319-46475-6_43},
  eprint    = {1603.08155},
}

@InProceedings{ULVL2016,
  author    = {Ulyanov, Dmitry and Lebedev, Vadim and Vedaldi, Andrea and Lempitsky, Viktor S.},
  booktitle = {International Conference on Machine Learning ({ICML})},
  title     = {Texture Networks: Feed-forward Synthesis of Textures and Stylized Images},
  year      = {2016},
  eprint    = {1603.03417},
  url       = {http://proceedings.mlr.press/v48/ulyanov16.html},
}

@Comment{jabref-meta: databaseType:bibtex;}
